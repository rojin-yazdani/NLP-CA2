{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis for the IMDb Movie Reviews dataset         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BOW technique based on unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "import re,string\n",
    "from bs4 import BeautifulSoup\n",
    "from random import shuffle \n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "from nltk import FreqDist\n",
    "\n",
    "from nltk import classify, NaiveBayesClassifier\n",
    "\n",
    "from nltk.metrics.scores import precision, recall, f_measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corpus has 2000 reviews, with 1000 having the 'pos' label and the remaining 1000 having the 'neg' label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 2000\n",
      "Review categories: ['neg', 'pos']\n",
      "Total positive reviews: 1000\n",
      "Total negative reviews: 1000\n",
      "Sample review file: neg/cv001_19502.txt\n"
     ]
    }
   ],
   "source": [
    "print (\"Total reviews:\", len(movie_reviews.fileids())) \n",
    "print (\"Review categories:\", movie_reviews.categories()) \n",
    "print (\"Total positive reviews:\", len(movie_reviews.fileids('pos'))) \n",
    "print (\"Total negative reviews:\", len(movie_reviews.fileids('neg'))) \n",
    "positive_review_file = movie_reviews.fileids('neg')[1] \n",
    "print (\"Sample review file:\", positive_review_file) \n",
    "#print(\"\\nContent of this sample review is :\", movie_reviews.raw(positive_review_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method below accepts a movie review as an input argument and returns tokens as an output.<br>\n",
    "Different parts of preprocessing step are: <br>\n",
    "- removing html tags\n",
    "- removing sentences between [] or () that were extra explanation\n",
    "- removing punctuation marks\n",
    "- removing stop words\n",
    "- extracting lemma and replace the main words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # removing the html strips\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    # removing the square [] , {} , () , «»\n",
    "    text = re.sub('\\[[^]]*\\]', ' ', text)\n",
    "    text = re.sub('\\([^]]*\\)', ' ', text)\n",
    "    text = re.sub('\\«[^]]*\\»', ' ', text)\n",
    "    text = re.sub('\\{[^]]*\\}', ' ', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove the punctuations\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # Lower the tokens\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    # Remove stopword\n",
    "    tokens = [word for word in tokens if not word in stopwords.words(\"english\")]\n",
    "    # Lemmatize\n",
    "    lemma = WordNetLemmatizer()\n",
    "    tokens = [lemma.lemmatize(word, pos = \"v\") for word in tokens]\n",
    "    tokens = [lemma.lemmatize(word, pos = \"n\") for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review_fileids = []\n",
    "pos_reviews = []\n",
    "for fileid in movie_reviews.fileids('pos'):\n",
    "    pos_review_fileids.append(fileid)\n",
    "    fileid_words_clean = clean_text(movie_reviews.raw(fileid))\n",
    "    pos_reviews.append(fileid_words_clean)\n",
    "\n",
    "neg_review_fileids = []\n",
    "neg_reviews = []\n",
    "for fileid in movie_reviews.fileids('neg'):\n",
    "    neg_review_fileids.append(fileid)\n",
    "    fileid_words_clean = clean_text(movie_reviews.raw(fileid))\n",
    "    neg_reviews.append(fileid_words_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BOW of sample review:\n",
      " ['film', 'adapt', 'comic', 'book', 'plenty', 'success', 'whether', 'superheroes', 'log', 'great', 'support', 'role', 'big', 'surprise', 'graham', 'cringe', 'first', 'time', 'open', 'mouth', 'imagine', 'attempt', 'irish', 'accent', 'actually', 'half', 'bad', 'film', 'however', 'good', 'r', 'strong', 'sexuality', 'language', 'drug', 'content']\n"
     ]
    }
   ],
   "source": [
    "#print(\"Raw text of sample review:\\n\", (movie_reviews.raw(pos_review_fileids[0])))\n",
    "print(\"\\nBOW of sample review:\\n\", (pos_reviews[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, tokens regardless of their places, are assuemd as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(words):\n",
    "    words_dictionary = dict([word, True] for word in words)    \n",
    "    return words_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample positive review:\n",
      " ({'film': True, 'adapt': True, 'comic': True, 'book': True, 'plenty': True, 'success': True, 'whether': True, 'superheroes': True, 'log': True, 'great': True, 'support': True, 'role': True, 'big': True, 'surprise': True, 'graham': True, 'cringe': True, 'first': True, 'time': True, 'open': True, 'mouth': True, 'imagine': True, 'attempt': True, 'irish': True, 'accent': True, 'actually': True, 'half': True, 'bad': True, 'however': True, 'good': True, 'r': True, 'strong': True, 'sexuality': True, 'language': True, 'drug': True, 'content': True}, 'pos')\n",
      "\n",
      "Sample negative review:\n",
      " ({'plot': True, 'two': True, 'teen': True, 'couple': True, 'go': True, 'church': True, 'party': True, 'drink': True, 'drive': True, 'get': True, 'accident': True, 'one': True, 'guy': True, 'die': True, 'girlfriend': True, 'continue': True, 'see': True, 'life': True, 'nightmare': True, 'deal': True, 'watch': True, 'movie': True, 'sorta': True, 'find': True, 'critique': True, 'generation': True, 'touch': True, 'cool': True, 'idea': True, 'present': True, 'bad': True, 'package': True, 'make': True, 'review': True, 'even': True, 'harder': True, 'write': True, 'since': True, 'generally': True, 'applaud': True, 'film': True, 'attempt': True, 'break': True, 'mold': True, 'mess': True, 'head': True}, 'neg')\n"
     ]
    }
   ],
   "source": [
    "pos_reviews_set = []\n",
    "for words in pos_reviews:\n",
    "    pos_reviews_set.append((bag_of_words(words), 'pos'))\n",
    "\n",
    "neg_reviews_set = []\n",
    "for words in neg_reviews:\n",
    "    neg_reviews_set.append((bag_of_words(words), 'neg'))\n",
    "\n",
    "print (\"\\nSample positive review:\\n\",pos_reviews_set[0])\n",
    "print (\"\\nSample negative review:\\n\", neg_reviews_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 1600 words were selected for training, while the final 400 words were chosen for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 1600 \n",
      "Test Size: 400\n"
     ]
    }
   ],
   "source": [
    "all_features = pos_reviews_set + neg_reviews_set\n",
    "shuffle(all_features)\n",
    "\n",
    "X_all = [list(item[0]) for item in all_features]\n",
    "y_all = [item[1] for item in all_features]\n",
    "\n",
    "X_train = X_all[:1600]\n",
    "y_train = y_all[:1600]\n",
    "X_test = X_all[1600:]\n",
    "y_test = y_all[1600:]\n",
    "print(\"Train Size:\", len(X_train), \"\\nTest Size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A technique for dividing data into test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_generator(X, y, k_fold):\n",
    "    subset_size = int(len(X) / k_fold)\n",
    "    #print(\"subset_size:\", subset_size)\n",
    "    for k in range(k_fold):\n",
    "        X_train = X[:k * subset_size] + X[(k + 1) * subset_size:]\n",
    "        X_valid = X[k * subset_size:][:subset_size]\n",
    "        y_train = y[:k * subset_size] + y[(k + 1) * subset_size:]\n",
    "        y_valid = y[k * subset_size:][:subset_size]\n",
    "\n",
    "        yield X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NaiveBayes model was called five times for various portions of the data, with fold=5 being assumed as the input argument for the above technique. <br> In the end, the accuracy was determined by averaging them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration :  1\n",
      "Accuracy: 0.75625\n",
      "\n",
      "Iteration :  2\n",
      "Accuracy: 0.76875\n",
      "\n",
      "Iteration :  3\n",
      "Accuracy: 0.775\n",
      "\n",
      "Iteration :  4\n",
      "Accuracy: 0.725\n",
      "\n",
      "Iteration :  5\n",
      "Accuracy: 0.759375\n",
      "\n",
      "Average Accuracy :  0.756875\n"
     ]
    }
   ],
   "source": [
    "k_fold=5\n",
    "counter=0\n",
    "sumAccuracy = 0\n",
    "for X_fold_train, y_fold_train, X_fold_valid, y_fold_valid in k_fold_generator(X_train, y_train, k_fold):\n",
    "    #print(len(X_fold_train), len(y_fold_train), len(X_fold_valid), len(y_fold_valid))\n",
    "    counter += 1\n",
    "    print(\"\\nIteration : \", counter)\n",
    "    \n",
    "    train_features = []\n",
    "    for i in range(len(X_fold_train)):\n",
    "        train_features.append((dict([word, True] for word in X_fold_train[i]), y_fold_train[i]))\n",
    "        \n",
    "    classifier = NaiveBayesClassifier.train(train_features) \n",
    "    classifier.train\n",
    "    \n",
    "    test_features = []\n",
    "    for i in range(len(X_fold_valid)):\n",
    "        test_features.append((dict([word, True] for word in X_fold_valid[i]), y_fold_valid[i]))  \n",
    "            \n",
    "    accuracy = classify.accuracy(classifier, test_features)\n",
    "    sumAccuracy += accuracy\n",
    "    print(\"Accuracy:\", accuracy) \n",
    "\n",
    "print(\"\\nAverage Accuracy : \", sumAccuracy/k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 features with the most effect were chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     14.7 : 1.0\n",
      "                 cameron = True              pos : neg    =     14.1 : 1.0\n",
      "                  truman = True              pos : neg    =     10.8 : 1.0\n",
      "            breathtaking = True              pos : neg    =     10.8 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n",
      "                  breast = True              neg : pos    =      9.8 : 1.0\n",
      "                 justice = True              pos : neg    =      9.5 : 1.0\n",
      "             wonderfully = True              pos : neg    =      8.8 : 1.0\n",
      "                 italian = True              pos : neg    =      8.2 : 1.0\n",
      "                  smooth = True              pos : neg    =      8.2 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (classifier.show_most_informative_features(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation was done using test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos Precision: 0.683206106870229\n",
      "pos Recall: 0.9040404040404041\n",
      "pos F1-Score: 0.7782608695652175\n",
      "neg Precision: 0.8623188405797102\n",
      "neg Recall: 0.5891089108910891\n",
      "neg F1-Score: 0.7\n",
      "Accuracy: 0.745\n"
     ]
    }
   ],
   "source": [
    "test_features = []\n",
    "for i in range(len(X_test)):\n",
    "    test_features.append((dict([word, True] for word in X_test[i]), y_test[i]))\n",
    "         \n",
    "y_pred, gold_labels = defaultdict(set), defaultdict(set)\n",
    "    \n",
    "for i, (features, label) in enumerate(test_features):\n",
    "    y_pred[classifier.classify(features)].add(i)\n",
    "    gold_labels[label].add(i) \n",
    "\n",
    "for label in y_pred:\n",
    "    print(label, 'Precision:', precision(gold_labels[label], y_pred[label]))\n",
    "    print(label, 'Recall:', recall(gold_labels[label], y_pred[label]))\n",
    "    print(label, 'F1-Score:', f_measure(gold_labels[label], y_pred[label]))\n",
    "accuracy = classify.accuracy(classifier, test_features)\n",
    "        \n",
    "print(\"Accuracy:\", accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
